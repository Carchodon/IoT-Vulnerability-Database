##imports generales
import mysql.connector
from database import db
from modificador import mod
import numpy as np

##imports de reconocimineto
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem.porter import PorterStemmer
import re
import string
########

##classification imprts
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn import metrics
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
import seaborn as sns; sns.set()

##Rocchio
from sklearn.neighbors.nearest_centroid import NearestCentroid
##Boosting
from sklearn.ensemble import GradientBoostingClassifier
##Bagging
from sklearn.ensemble import BaggingClassifier
##Naive Bayes
from sklearn.naive_bayes import MultinomialNB
##knn
from sklearn.neighbors import KNeighborsClassifier
##SVM
from sklearn.svm import LinearSVC
##decision tree 
from sklearn import tree
##random forest
from sklearn.ensemble import RandomForestClassifier


##cargamos el dataframe la tabla vulnerabilidades
modificador = mod()
df = modificador.get_dataframe_classified('vulnerabilidades')

##Define X and y
X = df.iloc[:,2:-1]
y = df['devType']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=43)

##obtenemos los datos que queremos en forma de lista para el train
descripcionesTrain = X_train['description'].tolist()
partTrain = X_train['part'].tolist()
vendorTrain = X_train['vendor'].tolist()
##juntamos en una sola lista con los datos que queremos que se utilizen en el clasificador(descripcion, part y vendor)
iterator = 0
for i in range(1,len(descripcionesTrain)):
  descripcionesTrain[iterator] = descripcionesTrain[iterator]+" "+partTrain[iterator]+" "+vendorTrain[iterator]
  iterator+=1


##obtenemos los datos que queremos en forma de lista para el test
descripcionesTest = X_test['description'].tolist()
partTest = X_test['part'].tolist()
vendorTest = X_test['vendor'].tolist()
##juntamos en una sola lista con los datos que queremos que se utilizen en el clasificador(descripcion, part y vendor)
iterator = 0
for i in range(1,len(descripcionesTest)):
  descripcionesTest[iterator] = descripcionesTest[iterator]+" "+partTest[iterator]+" "+vendorTest[iterator]
  iterator+=1

##Asignaciones para que todo funcione correctamnete
yy_train=y_train.to_numpy()
yy_test=y_test.to_numpy()
yy_train = yy_train.astype(np.int64)
yy_test = yy_test.astype(np.int64)

##Definir Pipeline con el clasificador que se quiera
text_clf = Pipeline([('vect', CountVectorizer()),
                     ('tfidf', TfidfTransformer()),
                     ('clf', RandomForestClassifier(n_estimators=100)),
                     ])
                     #('clf', NearestCentroid()),
                     #('clf', GradientBoostingClassifier(n_estimators=100)),
                     #('clf', BaggingClassifier(KNeighborsClassifier())),
                     #('clf', MultinomialNB()),
                     #('clf', KNeighborsClassifier()),
                     #('clf', LinearSVC()),
                     #('clf', tree.DecisionTreeClassifier()),
                     #('clf', RandomForestClassifier(n_estimators=100)),

##Fit y predict
aux = text_clf.fit(descripcionesTrain, yy_train)
predicted = text_clf.predict(descripcionesTest)


##print de la matriz de confusion y del report de la clasificacion
print(metrics.classification_report(yy_test, predicted))

cm = metrics.confusion_matrix(yy_test, predicted, labels=[0,1])
ax = sns.heatmap(cm, annot=True, fmt = "d", cmap="Spectral",linewidths=.5)
ax.set_xlabel('ACTUAL LABELS')
ax.set_ylabel('PREDICTED LABELS')
ax.xaxis.set_ticklabels(['0', '1'])
ax.yaxis.set_ticklabels(['0', '1'])
plt.show()
